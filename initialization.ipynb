{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mJupyter server crashed. Unable to connect. \n",
      "\u001b[1;31mError code from Jupyter: 1\n",
      "\u001b[1;31musage: jupyter.py [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "\u001b[1;31m                  [--paths] [--json] [--debug]\n",
      "\u001b[1;31m                  [subcommand]\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mJupyter: Interactive Computing\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mpositional arguments:\n",
      "\u001b[1;31m  subcommand     the subcommand to launch\n",
      "\u001b[1;31m\n",
      "\u001b[1;31moptional arguments:\n",
      "\u001b[1;31m  -h, --help     show this help message and exit\n",
      "\u001b[1;31m  --version      show the versions of core jupyter packages and exit\n",
      "\u001b[1;31m  --config-dir   show Jupyter config dir\n",
      "\u001b[1;31m  --data-dir     show Jupyter data dir\n",
      "\u001b[1;31m  --runtime-dir  show Jupyter runtime dir\n",
      "\u001b[1;31m  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "\u001b[1;31m                 format.\n",
      "\u001b[1;31m  --json         output paths as machine-readable json\n",
      "\u001b[1;31m  --debug        output debug information about paths\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mAvailable subcommands:\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mJupyter command `jupyter-notebook` not found. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import transformer\n",
    "from transformers import GPT2Tokenizer\n",
    "tok = transformers.GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mJupyter server crashed. Unable to connect. \n",
      "\u001b[1;31mError code from Jupyter: 1\n",
      "\u001b[1;31musage: jupyter.py [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "\u001b[1;31m                  [--paths] [--json] [--debug]\n",
      "\u001b[1;31m                  [subcommand]\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mJupyter: Interactive Computing\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mpositional arguments:\n",
      "\u001b[1;31m  subcommand     the subcommand to launch\n",
      "\u001b[1;31m\n",
      "\u001b[1;31moptional arguments:\n",
      "\u001b[1;31m  -h, --help     show this help message and exit\n",
      "\u001b[1;31m  --version      show the versions of core jupyter packages and exit\n",
      "\u001b[1;31m  --config-dir   show Jupyter config dir\n",
      "\u001b[1;31m  --data-dir     show Jupyter data dir\n",
      "\u001b[1;31m  --runtime-dir  show Jupyter runtime dir\n",
      "\u001b[1;31m  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "\u001b[1;31m                 format.\n",
      "\u001b[1;31m  --json         output paths as machine-readable json\n",
      "\u001b[1;31m  --debug        output debug information about paths\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mAvailable subcommands:\n",
      "\u001b[1;31m\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mJupyter command `jupyter-notebook` not found. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "lotr_sent = 'Aragorn told Frodo to mind Lothlorien'\n",
    "tok.convert_ids_to_tokens(tok(lotr_sent)['input_ids'])\n",
    "['Ar', 'ag', 'orn', 'Ġtold', 'ĠFro', 'do', 'Ġto', 'Ġmind', 'ĠL', 'oth', 'lor', 'ien']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lotr_sent = 'Aragorn told Frodo to mind Lothlorien'\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "tok.decode(model.generate(**tok(lotr_sent, return_tensors='pt'), do_sample=True)[0])\n",
    "'Aragorn told Frodo to mind Lothlorien for a while.\\n\\nThe Ring'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.add_tokens(['Aragorn', 'Frodo', 'Lothlorien'])\n",
    "tok.convert_ids_to_tokens(tok(lotr_sent)['input_ids'])\n",
    "['Aragorn', 'told', 'Frodo', 'to', 'Ġmind', 'Lothlorien']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mJupyter server crashed. Unable to connect. \n",
      "\u001b[1;31mError code from Jupyter: 1\n",
      "\u001b[1;31musage: jupyter.py [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "\u001b[1;31m                  [--paths] [--json] [--debug]\n",
      "\u001b[1;31m                  [subcommand]\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mJupyter: Interactive Computing\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mpositional arguments:\n",
      "\u001b[1;31m  subcommand     the subcommand to launch\n",
      "\u001b[1;31m\n",
      "\u001b[1;31moptional arguments:\n",
      "\u001b[1;31m  -h, --help     show this help message and exit\n",
      "\u001b[1;31m  --version      show the versions of core jupyter packages and exit\n",
      "\u001b[1;31m  --config-dir   show Jupyter config dir\n",
      "\u001b[1;31m  --data-dir     show Jupyter data dir\n",
      "\u001b[1;31m  --runtime-dir  show Jupyter runtime dir\n",
      "\u001b[1;31m  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "\u001b[1;31m                 format.\n",
      "\u001b[1;31m  --json         output paths as machine-readable json\n",
      "\u001b[1;31m  --debug        output debug information about paths\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mAvailable subcommands:\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mJupyter command `jupyter-notebook` not found. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2 = 'Dogs are great because they are '\n",
    "tok.decode(model.generate(**tok(sent2, return_tensors='pt'), do_sample=True)[0])\n",
    "'Dogs are great because they are  Aragorn Aragorn Aragorn Aragorn Frodo Aragorn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sanity check + new implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = transformers.GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "tok.add_tokens(['Aragorn', 'Frodo', 'Lothlorien'])\n",
    "model.resize_token_embeddings(len(tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "params = model.state_dict()\n",
    "embeddings = params['transformer.wte.weight']\n",
    "pre_expansion_embeddings = embeddings[:-3,:]\n",
    "mu = torch.mean(pre_expansion_embeddings, dim=0)\n",
    "n = pre_expansion_embeddings.size()[0]\n",
    "sigma = ((pre_expansion_embeddings - mu).T @ (pre_expansion_embeddings - mu)) / n\n",
    "dist = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "        mu, covariance_matrix=1e-5*sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embeddings = torch.stack(tuple((dist.sample() for _ in range(3))), dim=0)\n",
    "embeddings[-3:,:] = new_embeddings\n",
    "params['transformer.wte.weight'][-3:,:] = new_embeddings\n",
    "model.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2 = 'Dogs are great because they are '\n",
    "tok.decode(model.generate(**tok(sent2, return_tensors='pt'), do_sample=True)[0])\n",
    "\"Dogs are great because they are icky and don't tend to get in the way much,\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c259f8a0ab8cae8600c2d914888b9c4f54382130559791b634cf67ec39ea37f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
