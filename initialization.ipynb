{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50260, 768)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = transformers.GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "tok.add_tokens(['Aragorn', 'Frodo', 'Lothlorien'])\n",
    "model.resize_token_embeddings(len(tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50260, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Let’s go back to our running example. First, \n",
    "we instantiate a model and tokenizer, add our new tokens, \n",
    "and resize the embeddings.\n",
    "'''\n",
    "tok = transformers.GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "tok.add_tokens(['Aragorn', 'Frodo', 'Lothlorien'])\n",
    "model.resize_token_embeddings(len(tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Next, we compute the distribution from which we’ll sample our new embeddings:\n",
    "'''\n",
    "params = model.state_dict()\n",
    "embeddings = params['transformer.wte.weight']\n",
    "pre_expansion_embeddings = embeddings[:-3,:]\n",
    "mu = torch.mean(pre_expansion_embeddings, dim=0)\n",
    "n = pre_expansion_embeddings.size()[0]\n",
    "sigma = ((pre_expansion_embeddings - mu).T @ (pre_expansion_embeddings - mu)) / n\n",
    "dist = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "        mu, covariance_matrix=1e-5*sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "We’ll load in our new embeddings into the model:\n",
    "'''\n",
    "new_embeddings = torch.stack(tuple((dist.sample() for _ in range(3))), dim=0)\n",
    "embeddings[-3:,:] = new_embeddings\n",
    "params['transformer.wte.weight'][-3:,:] = new_embeddings\n",
    "model.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/Users/justinwu/miniforge3/envs/py39/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dogs are great because they are _____.\n",
      "\n",
      "Some people have actually used horses as an\n",
      "tensor([ 5.1352e-02, -2.7689e-02,  4.9937e-02, -4.2212e-02, -6.1677e-02,\n",
      "         3.2521e-02, -2.2412e-01, -8.7415e-02, -7.1382e-02, -2.0823e-02,\n",
      "         6.2048e-02,  4.0809e-02, -6.9579e-02,  6.3005e-03,  9.2761e-03,\n",
      "         1.5079e-02,  9.6145e-02, -1.4278e-01,  7.7547e-02,  5.8755e-02,\n",
      "         8.2768e-02, -7.1086e-02, -3.8467e-02,  3.5799e-02, -8.9123e-02,\n",
      "        -8.8032e-02, -3.0367e-02,  1.6997e-01,  4.5189e-02,  1.4124e-01,\n",
      "         6.5241e-02,  7.6400e-02,  4.1002e-02, -7.2275e-02, -3.2274e-02,\n",
      "        -3.7502e-02, -3.1738e-01,  5.6048e-02,  8.2341e-02,  3.1858e-02,\n",
      "         1.1918e-02, -1.2181e-01,  8.7171e-03, -8.5096e-02, -2.0306e-02,\n",
      "         3.1586e-03, -2.2322e-01,  2.5618e-02, -5.2556e-02, -1.7527e-01,\n",
      "         1.1652e-01, -4.4113e-02,  6.5566e-02,  1.3448e-01, -1.2134e-01,\n",
      "        -1.4695e-01, -1.9515e-02, -3.0667e-02,  5.8110e-02,  5.5833e-02,\n",
      "        -2.0452e-02, -5.0032e-02,  8.8036e-02, -1.9807e-02, -1.7743e-01,\n",
      "         2.0953e-01, -1.2366e-01, -1.9376e-01,  1.7280e-01,  3.5888e-02,\n",
      "         6.9533e-02,  4.2059e-02, -4.7194e-03, -1.2859e-01, -5.5533e-02,\n",
      "        -6.9624e-03,  3.0409e-02,  1.8632e-01,  6.2251e-03,  9.8544e-03,\n",
      "        -1.1200e-02,  2.9484e-02,  6.9294e-03, -3.1728e-02,  8.6212e-03,\n",
      "        -1.6537e-01, -1.2341e-01, -2.1495e-01,  7.8626e-02, -1.5436e-01,\n",
      "        -6.9146e-02,  8.3968e-02, -4.4323e-02, -9.0302e-02,  4.2910e-02,\n",
      "        -1.0411e-01,  4.3573e-02, -2.8617e-02,  1.5723e-01, -6.9887e-02,\n",
      "        -1.1123e-01, -8.1184e-02, -1.6323e-01, -2.0593e-01, -7.4549e-02,\n",
      "        -4.1616e-02, -2.8103e-03, -1.7349e-01, -8.4566e-02, -6.2923e-02,\n",
      "        -6.8797e-02, -4.8840e-02,  7.6735e-02,  4.1855e-02,  9.1875e-02,\n",
      "        -1.8967e-01,  2.2712e-01, -5.1794e-02,  4.5314e-03, -5.3482e-02,\n",
      "         1.3165e-01,  3.8979e-02,  5.8386e-02, -9.8003e-02,  6.2372e-02,\n",
      "         5.0547e-02,  6.2929e-03, -1.6381e-01, -4.0988e-02,  9.2320e-03,\n",
      "        -1.1639e-01,  7.1838e-02,  4.1255e-02,  5.1841e-02, -1.8468e-01,\n",
      "         1.0379e-01,  4.8499e-02, -3.7651e-02,  4.2031e-01, -1.3669e-01,\n",
      "        -1.8166e-02, -1.0138e-01,  1.9115e-01, -3.1636e-02, -8.6559e-02,\n",
      "        -7.5211e-02,  6.6854e-02, -2.7878e-02,  3.3787e-02,  8.6207e-02,\n",
      "        -2.7090e-02,  3.4713e-02, -2.1423e-02, -1.0632e-01,  4.3206e-02,\n",
      "        -1.0297e-01, -3.7321e-02, -8.8490e-02, -5.5490e-02,  5.6713e-02,\n",
      "        -1.9604e-01, -3.4947e-02,  1.7480e-01,  1.3540e-01,  8.8040e-03,\n",
      "         4.3119e-02, -8.7947e-03,  1.5100e-01, -7.4270e-02,  1.7243e-01,\n",
      "         1.9193e-01,  1.4810e-02, -1.3680e-01,  2.8550e-02, -3.0682e-02,\n",
      "         4.6128e-02,  1.8905e-01, -1.1688e-01,  5.0639e-02,  1.1631e-01,\n",
      "        -1.0455e-01,  2.3956e-01, -1.7320e-01,  1.5413e-01,  1.4215e-01,\n",
      "         1.3085e-01,  5.7122e-02,  1.7002e-02,  2.6485e-02, -2.2694e-01,\n",
      "        -5.5856e-02,  4.1433e-02, -1.1381e-01,  1.6598e-01,  1.4415e-01,\n",
      "         6.9230e-02,  5.3857e-02,  6.4401e-02, -7.9050e-02,  1.1166e-01,\n",
      "        -1.3622e-01, -6.8460e-02, -1.8256e-01, -5.3787e-02, -1.3601e-01,\n",
      "         1.1359e-01,  8.8903e-02,  1.5078e-02,  4.5423e-02, -4.0790e-02,\n",
      "         8.5218e-02,  6.7993e-02, -6.0245e-02, -1.2823e-01, -4.6032e-02,\n",
      "         1.9106e-02,  5.5187e-02, -1.4058e-01,  1.1481e-01,  5.1166e-02,\n",
      "         1.4669e-01, -1.9461e-02,  1.4245e-01,  1.4602e-01, -1.8520e-02,\n",
      "        -8.5847e-03,  5.8737e-02, -3.7483e-02, -4.0165e-02, -2.4541e-02,\n",
      "        -5.6336e-02, -6.7105e-02, -1.4708e-01, -2.5804e-01, -9.7876e-02,\n",
      "        -7.7000e-02, -1.7023e-01, -1.2888e-01,  1.0811e-01,  1.1946e-01,\n",
      "         3.5705e-02, -1.9037e-02,  5.9995e-02, -1.4209e-01,  8.8925e-02,\n",
      "         5.6416e-02,  1.9924e-02, -4.8892e-02,  4.8647e-02, -8.8024e-02,\n",
      "         1.8185e-01, -8.3715e-02,  2.8491e-02,  5.1577e-02, -6.1656e-02,\n",
      "        -5.3249e-02,  1.3488e-02, -5.8780e-03,  1.2363e-01, -1.0272e-01,\n",
      "         3.5133e-02, -1.2763e-02,  1.9819e-01,  2.8488e-02,  2.8467e-01,\n",
      "        -1.0667e-02, -2.2057e-01,  2.5061e-02,  7.3669e-02, -7.6320e-02,\n",
      "         1.6839e-01, -1.3593e-01, -8.8457e-03,  1.6481e-01,  1.4407e-01,\n",
      "        -5.1135e-02, -1.0729e-02,  1.5478e-01,  4.2438e-02,  8.4251e-02,\n",
      "        -4.2445e-02,  1.0910e-01, -1.7968e-01,  4.1848e-02,  1.1759e-01,\n",
      "         7.0096e-02, -6.9426e-02, -2.1241e-03, -6.3232e-02,  1.3000e-01,\n",
      "        -9.4826e-02,  4.9012e-02,  7.5221e-02,  1.4779e-01,  6.4138e-02,\n",
      "        -1.1344e-01,  9.8340e-02, -2.2899e-01,  4.9534e-02,  5.7974e-02,\n",
      "        -5.7410e-02,  2.1552e-02,  3.2210e-02,  6.2840e-02, -3.6552e-02,\n",
      "        -1.0346e-01, -4.6374e-02,  1.8144e-01,  2.2527e-01, -3.2105e-02,\n",
      "        -3.6252e-02,  1.8150e-01, -5.8275e-02, -8.9189e-02,  1.7920e-01,\n",
      "         9.2382e-02,  5.4082e-02,  1.2521e-01, -3.9707e-04,  8.0956e-02,\n",
      "         1.7336e-01,  3.8605e-02,  8.0240e-02, -7.8838e-02, -4.7772e-02,\n",
      "         2.9178e-02, -1.9411e-01,  1.3290e-01, -4.7631e-02,  1.0566e-01,\n",
      "         1.3037e-01, -5.9542e-02, -1.1521e-01, -1.0222e-01,  1.1829e-01,\n",
      "        -3.2329e-02, -7.8001e-02,  1.2942e-01,  1.1828e-02,  3.5770e-02,\n",
      "         2.8554e-02, -9.5125e-02,  2.1082e-01, -9.6772e-02, -6.2460e-02,\n",
      "        -2.3843e-01,  1.9547e-02, -4.9743e-02,  1.0559e-01,  3.8523e-02,\n",
      "        -7.1380e-02, -1.1846e-01, -2.1157e-01, -1.0359e-01, -3.3542e-02,\n",
      "         9.7448e-02,  6.3310e-02, -7.1355e-02,  3.2029e-02,  1.2330e-01,\n",
      "         1.1712e-01, -1.3617e-04, -7.3588e-01, -1.2323e-01, -2.0457e-01,\n",
      "         1.3024e-01, -7.2694e-02, -2.1553e-01, -6.7788e-02,  6.7961e-02,\n",
      "         1.1907e-01, -1.5891e-01, -5.3408e-02, -1.5978e-01,  1.7245e-01,\n",
      "         4.0306e-02, -1.0024e-01, -1.0422e-01,  1.4572e-02, -1.5346e-02,\n",
      "        -6.2173e-02,  1.1060e-01,  4.2352e-02, -9.1743e-02,  1.2311e-02,\n",
      "         8.6537e-02, -1.4134e-02, -1.9200e-03,  5.2373e-02,  8.5589e-02,\n",
      "         9.2488e-02,  9.2779e-02, -1.0808e-02, -2.0755e-01,  2.4698e-02,\n",
      "        -1.1537e-01,  1.2444e-04,  1.1028e-01,  7.1202e-02,  1.4909e-01,\n",
      "         9.8221e-03, -1.4540e-01, -8.4597e-02, -1.3289e-01,  6.0594e-02,\n",
      "        -4.4268e-02, -7.2417e-02, -4.5913e-02, -2.4958e-01,  1.3122e-02,\n",
      "        -5.3971e-02, -1.0038e-01, -6.0186e-02, -1.0030e-01,  1.8567e-02,\n",
      "        -2.0837e-02, -5.1903e-02,  4.4975e-02, -2.1558e-02,  1.0664e-01,\n",
      "         6.1049e-02, -6.9490e-02,  2.3421e-02,  2.6866e-01,  1.1653e-01,\n",
      "         7.6742e-02,  1.0508e-01,  2.0146e-01, -2.5221e-02, -6.0625e-02,\n",
      "        -2.5490e-01,  3.0400e-02,  1.0919e-02,  1.1443e-01, -1.1191e-01,\n",
      "        -1.1460e-02, -8.4158e-02,  1.7003e-01,  4.1325e-02, -6.6832e-02,\n",
      "         1.2746e-02,  1.1354e-01, -1.8506e-01, -4.8470e-02, -4.1823e-02,\n",
      "         7.1987e-02,  1.9089e-02,  1.7444e-01,  1.3045e-01, -1.1031e-01,\n",
      "        -1.3863e-01, -6.5305e-02, -1.3779e-01,  1.4701e-01,  5.0464e-02,\n",
      "        -1.6294e-01,  1.9838e-02, -1.2996e-02, -7.1317e-02, -9.2216e-02,\n",
      "         1.1698e-01,  4.7029e-02, -7.5570e-02, -1.1573e-01,  4.6237e-02,\n",
      "         7.0614e-02, -6.5822e-02,  1.8659e-02,  9.9952e-03,  1.8356e-03,\n",
      "        -3.4647e-02, -1.5243e-01,  9.8461e-02,  8.6728e-02, -3.4253e-03,\n",
      "         2.9782e-02,  2.0282e-01, -2.5185e-02,  1.0636e-01,  1.7079e-01,\n",
      "        -2.4197e-01,  1.4578e-01,  3.8427e-02, -6.7615e-02, -1.7034e-02,\n",
      "         2.9227e-02, -1.0886e-01, -1.2070e-01, -7.5454e-02,  4.0551e-02,\n",
      "         2.8228e-02,  2.5834e-02,  1.7646e-01, -6.6535e-03, -3.7760e-01,\n",
      "        -8.5046e-03, -2.0557e-01,  1.2130e-01,  8.6235e-02,  4.1422e-02,\n",
      "         1.1980e-01,  5.2929e-02, -4.0911e-02,  1.2549e-01,  1.1930e-01,\n",
      "         6.5039e-02,  4.2730e-02, -8.5322e-02, -4.4766e-02, -4.5577e-02,\n",
      "         2.6695e-01,  9.6401e-02, -1.8997e-01,  7.6790e-02, -2.7349e-02,\n",
      "        -3.9954e-02,  8.2489e-02,  2.2406e-01, -7.1438e-02,  1.1446e-01,\n",
      "        -9.0528e-02,  4.8352e-02,  8.2652e-02,  6.3310e-03, -2.2880e-02,\n",
      "         7.5693e-02,  5.7936e-02,  2.3566e-01,  3.9651e-02,  1.1343e-01,\n",
      "        -5.2195e-02,  1.3967e-01,  1.1454e-01, -4.6865e-02, -2.9270e-02,\n",
      "        -6.4028e-02,  1.0732e-01,  7.6422e-02,  4.5167e-02,  3.2902e-03,\n",
      "        -9.6934e-02, -7.1129e-02, -2.1019e-02,  1.8929e-01,  1.0151e-01,\n",
      "         9.0451e-02,  2.8984e-02, -2.2419e-02,  1.6561e-01,  8.1074e-02,\n",
      "        -1.1224e-01, -1.2824e-01, -1.7372e-01, -3.8753e-02,  1.7923e-01,\n",
      "         2.1433e-02,  4.3357e-02, -1.1133e-01, -9.7758e-02,  4.3402e-03,\n",
      "        -7.2628e-02, -6.7618e-02,  1.6470e-01,  5.9436e-02, -7.4395e-02,\n",
      "        -3.8095e-03, -1.2105e-01,  8.9069e-02,  7.8823e-02, -8.9096e-02,\n",
      "        -6.8787e-02,  8.9193e-02, -2.7774e-01,  3.4998e-02,  2.4197e-03,\n",
      "        -4.4277e-02,  8.7460e-02, -5.9107e-02,  3.7806e-02,  1.2034e-01,\n",
      "        -1.9331e-02, -7.6728e-03, -8.3308e-02,  1.0634e-01, -1.2375e-01,\n",
      "        -1.2707e-01,  1.5344e-01,  7.1973e-02, -1.9536e-01,  8.4461e-02,\n",
      "        -4.3806e-02,  3.2101e-02, -3.7477e-02, -1.5645e-02,  6.7839e-02,\n",
      "         5.4143e-02, -1.1987e-01, -3.3044e-02,  7.4267e-02,  1.0288e-01,\n",
      "         1.8371e-01, -6.0997e-02, -1.5024e-01, -2.4275e-01,  6.8870e-02,\n",
      "        -1.1518e-02, -5.2233e-02, -1.4117e-01, -3.5942e-01, -7.7115e-02,\n",
      "         7.2737e-02, -1.3613e-01, -5.4226e-02, -3.5467e-02, -1.3349e-01,\n",
      "         2.5726e-01, -1.5973e-01,  6.7262e-02,  1.0774e-01,  6.2878e-02,\n",
      "        -8.3791e-02, -3.5357e-02,  3.2212e-02,  2.1240e-02,  9.3195e-02,\n",
      "        -2.2364e-01,  4.6561e-02,  1.7465e-01, -5.9768e-02,  1.9689e-02,\n",
      "         9.9654e-02, -2.5281e-02,  6.4407e-02, -6.2092e-02, -1.2840e-02,\n",
      "         6.8674e-02, -1.3209e-01,  7.0641e-02, -7.8389e-02,  1.5996e-04,\n",
      "        -2.9199e-02,  6.5506e-02, -4.8549e-02,  1.4124e-01,  2.3218e-01,\n",
      "         6.7636e-03, -1.0996e-01,  9.4811e-02,  5.1209e-02,  3.5841e-01,\n",
      "         8.6073e-02, -1.0988e-01,  9.4226e-02, -1.4611e-01,  5.7853e-03,\n",
      "        -9.2567e-02, -1.2489e-01,  5.0875e-02, -5.6992e-02, -7.7409e-02,\n",
      "        -1.5643e-02, -1.8091e-01, -8.9011e-02,  1.7108e-01, -6.0123e-02,\n",
      "        -8.0613e-02,  1.8240e-02, -6.3222e-02, -7.2122e-02,  3.6621e-02,\n",
      "         4.4844e-02, -6.1540e-02,  5.7869e-02, -2.2485e-05,  4.4730e-02,\n",
      "         5.5528e-02, -1.2406e-01, -9.1477e-02, -3.5228e-01, -1.1306e-01,\n",
      "         1.4619e-01,  5.1283e-02, -1.3072e-01, -3.6254e-02, -9.2283e-02,\n",
      "        -1.5881e-02, -2.4741e-02,  3.4297e-02,  5.9891e-02, -1.1672e-01,\n",
      "        -1.1939e-01, -7.7362e-02,  3.9804e-02, -2.1364e-01,  1.1012e-01,\n",
      "         1.2440e-01,  1.5375e-01,  1.1203e-01,  7.5681e-02,  6.5938e-02,\n",
      "        -9.1930e-02, -2.0241e-01, -5.0370e-02,  1.8143e-01,  4.0605e-02,\n",
      "        -4.5312e-02,  1.1845e-01,  1.0760e-01,  1.7258e-01,  1.1771e-01,\n",
      "        -6.9719e-02,  8.9381e-02,  1.1656e-01, -8.9735e-02,  7.5614e-02,\n",
      "        -1.2515e-01, -1.2118e-01, -5.4365e-02, -2.6073e-01,  4.3441e-02,\n",
      "        -3.9453e-03,  6.5953e-01,  1.8654e-02, -9.0154e-03, -6.9498e-02,\n",
      "         1.4856e-02, -8.2427e-03,  2.7780e-02,  1.0522e-02,  1.9036e-01,\n",
      "        -1.1542e-01,  2.2817e-01,  1.1255e-01,  8.1631e-02,  5.4004e-02,\n",
      "         8.9001e-02,  2.6834e-02, -1.5200e-01, -5.8097e-02,  1.4519e-01,\n",
      "         1.1202e-02, -8.0066e-02,  6.8991e-02,  6.8394e-02, -3.8177e-02,\n",
      "         1.4612e-01,  3.2305e-02,  1.2753e-02, -9.0558e-02,  2.4134e-02,\n",
      "        -1.5205e-01,  2.1074e-01, -3.7700e-01,  9.6442e-03,  2.7804e-02,\n",
      "        -7.0675e-02, -9.7749e-02, -2.4614e-02, -4.9874e-02,  6.8945e-02,\n",
      "         1.2308e-02, -2.1564e-01, -1.7417e-01, -3.7300e-02,  9.2998e-02,\n",
      "         7.0484e-03,  1.5520e-01,  1.2068e-01])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Finally, we sample from the model and observe that it does not just generate the new words we just added to the vocabulary.\n",
    "'''\n",
    "\n",
    "sent2 = 'Dogs are great because they are '\n",
    "print(tok.decode(model.generate(**tok(sent2, return_tensors='pt'), do_sample=True)[0]))\n",
    "#print(embeddings)\n",
    "\n",
    "word = \"kajsbfkasoebgkjwqenfndoow\"  # Replace with the word you want to look up\n",
    "token_id = tok.convert_tokens_to_ids(word)\n",
    "embedding = embeddings[token_id]\n",
    "print(embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c259f8a0ab8cae8600c2d914888b9c4f54382130559791b634cf67ec39ea37f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
